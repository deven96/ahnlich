"use strict";(self.webpackChunkahnlich_web=self.webpackChunkahnlich_web||[]).push([[5665],{28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var r=i(96540);const s={},t=r.createContext(s);function o(e){const n=r.useContext(t);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(t.Provider,{value:n},e.children)}},63565:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"client-libraries/python/request-ai/info-server","title":"Info Server","description":"How to request server information from the Ahnlich AI Service using the Python client.","source":"@site/docs/client-libraries/python/request-ai/info-server.md","sourceDirName":"client-libraries/python/request-ai","slug":"/client-libraries/python/request-ai/info-server","permalink":"/docs/client-libraries/python/request-ai/info-server","draft":false,"unlisted":false,"editUrl":"https://github.com/deven96/ahnlich/tree/main/web/ahnlich-web/docs/client-libraries/python/request-ai/info-server.md","tags":[],"version":"current","frontMatter":{"title":"Info Server"},"sidebar":"docsSidebar","previous":{"title":"Ping","permalink":"/docs/client-libraries/python/request-ai/ping"},"next":{"title":"List Stores","permalink":"/docs/client-libraries/python/request-ai/list-stores"}}');var s=i(74848),t=i(28453);const o={title:"Info Server"},a="Info Server",l={},c=[{value:"Define Request Parameters",id:"define-request-parameters",level:2},{value:"Define Response Handling",id:"define-response-handling",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components},{Details:i}=n;return i||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"info-server",children:"Info Server"})}),"\n",(0,s.jsx)(n.p,{children:"How to request server information from the Ahnlich AI Service using the Python client."}),"\n",(0,s.jsx)(n.p,{children:"AI Requests are the fundamental way to interact with the Ahnlich AI backend. They provide low-level functionality such as checking availability, inspecting runtime configuration, and requesting embeddings or search results."}),"\n",(0,s.jsxs)(n.p,{children:["In the Ahnlich Python client programming model, AI requests are made through stubs generated from the gRPC definitions. Each request must be wrapped in an ",(0,s.jsx)(n.code,{children:"async"})," function, as communication is asynchronous."]}),"\n",(0,s.jsx)(n.p,{children:"The following example demonstrates how to make an Info Server request."}),"\n",(0,s.jsxs)(i,{children:[(0,s.jsx)("summary",{children:"Click to expand source code"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:"import asyncio\nfrom grpclib.client import Channel\nfrom ahnlich_client_py.grpc.services.ai_service import AiServiceStub\nfrom ahnlich_client_py.grpc.ai import query as ai_query\n\n\nasync def info_server():\n  async with Channel(host=\"127.0.0.1\", port=1370) as channel:\n      client = AiServiceStub(channel)\n      response = await client.info_server(ai_query.InfoServer())\n      print(response) #InfoServer(info=ServerInfo(address='Ok(0.0.0.0:1370)', version='0.1.0', limit=10073741824, remaining=10067931251))\n\n\nif __name__ == \"__main__\":\n  asyncio.run(info_server())\n"})})]}),"\n",(0,s.jsx)(n.h2,{id:"define-request-parameters",children:"Define Request Parameters"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"InfoServer"})," request does not require any parameters.\nIt is used primarily for ",(0,s.jsx)(n.strong,{children:"diagnostics and service discovery"}),", returning metadata such as:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Server version"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Supported models"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Available features"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Runtime configuration details"}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"define-response-handling",children:"Define Response Handling"}),"\n",(0,s.jsxs)(n.p,{children:["The response from ",(0,s.jsx)(n.code,{children:"info_server()"})," is serializable and can be logged or stored.\nIt should be treated as ",(0,s.jsx)(n.strong,{children:"read-only diagnostic data"})," and is most commonly used when:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Debugging compatibility issues"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Verifying that the AI service is initialized"}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Inspecting model availability before embedding or search requests"}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}}}]);