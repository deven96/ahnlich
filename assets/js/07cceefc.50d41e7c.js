"use strict";(self.webpackChunkahnlich_web=self.webpackChunkahnlich_web||[]).push([[957],{14753:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/images/jaeger-1-1350bfeef0feb261ca2c2c02a2f4ad1b.png"},15767:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/images/jaeger-7-d52abe5122ee9485229762cf381c31bf.png"},16270:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/images/jaeger-6-c08a751c46dc04651a34c04f86ec606c.png"},27749:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/images/jaeger-5-f03e9bf22b7f9f6ea42cf6094fdeaf83.png"},28453:(e,n,r)=>{r.d(n,{R:()=>a,x:()=>o});var s=r(96540);const t={},i=s.createContext(t);function a(e){const n=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),s.createElement(i.Provider,{value:n},e.children)}},57322:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/images/jaeger-2-f420fe131b56af8ae52046ea7ee3c37f.png"},84651:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>l});const s=JSON.parse('{"id":"components/distributed-tracing/using-jaeger","title":"Using Jaeger","description":"Jaeger is a popular open-source distributed tracing system. We use the all-in-one Docker image to collect and visualize traces for both DB and AI operations.","source":"@site/docs/components/distributed-tracing/using-jaeger.md","sourceDirName":"components/distributed-tracing","slug":"/components/distributed-tracing/using-jaeger","permalink":"/docs/components/distributed-tracing/using-jaeger","draft":false,"unlisted":false,"editUrl":"https://github.com/deven96/ahnlich/tree/main/web/ahnlich-web/docs/components/distributed-tracing/using-jaeger.md","tags":[],"version":"current","frontMatter":{"title":"Using Jaeger"},"sidebar":"docsSidebar","previous":{"title":"Tracing in Ahnlich AI","permalink":"/docs/components/distributed-tracing/ahnlich-ai"},"next":{"title":"Client libraries","permalink":"/docs/client-libraries/"}}');var t=r(74848),i=r(28453);const a={title:"Using Jaeger"},o="Using Jaeger all-in-one",c={},l=[{value:"Docker Compose snippet:",id:"docker-compose-snippet",level:3},{value:"Steps",id:"steps",level:3},{value:"Example AI &amp; DB Queries (from CLI)",id:"example-ai--db-queries-from-cli",level:2},{value:"DB Query Example",id:"db-query-example",level:3},{value:"AI Query Example",id:"ai-query-example",level:3},{value:"Program Implementing the Queries",id:"program-implementing-the-queries",level:2},{value:"Code Explanation",id:"code-explanation",level:2},{value:"Viewing Spans in Jaeger",id:"viewing-spans-in-jaeger",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"using-jaeger-all-in-one",children:"Using Jaeger all-in-one"})}),"\n",(0,t.jsxs)(n.p,{children:["Jaeger is a popular open-source ",(0,t.jsx)(n.strong,{children:"distributed tracing system"}),". We use the ",(0,t.jsx)(n.strong,{children:"all-in-one Docker image"})," to collect and visualize traces for both DB and AI operations."]}),"\n",(0,t.jsx)(n.h3,{id:"docker-compose-snippet",children:"Docker Compose snippet:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-docker",children:'jaeger:\n  image: jaegertracing/all-in-one:latest\n  ports:\n    - "16686:16686"  # UI\n    - "4317:4317"    # OTLP gRPC\n'})}),"\n",(0,t.jsx)(n.h3,{id:"steps",children:"Steps"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Make sure your other services are running (ahnlich-db on 1369, ahnlich-ai on 1370)."}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Run Jaeger with:"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"  docker-compose up -d jaeger\n"})}),"\n",(0,t.jsxs)(n.ol,{start:"3",children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Open the ",(0,t.jsx)(n.strong,{children:"Jaeger UI"})," in your browser: ",(0,t.jsx)(n.a,{href:"http://localhost:16686",children:"http://localhost:16686"})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Select the service ",(0,t.jsx)(n.strong,{children:"tracing-client"})," to see traces from your Python workflow."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"example-ai--db-queries-from-cli",children:"Example AI & DB Queries (from CLI)"}),"\n",(0,t.jsx)(n.h3,{id:"db-query-example",children:"DB Query Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'CREATESTORE db_store_20250915143036 DIMENSION 512\nSET (([0.1, 0.1, ..., 0.1], {text: "This is the life of Alice"})) IN db_store_20250915143036\nLISTSTORES\n'})}),"\n",(0,t.jsx)(n.h3,{id:"ai-query-example",children:"AI Query Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:'CREATESTORE ai_store_20250915143036 QUERYMODEL all-minilm-l6-v2 INDEXMODEL all-minilm-l6-v2 PREDICATES (author, category)\nSET ((["Jordan One"], {brand: Nike}), (["Yeezey"], {brand: Adidas})) IN ai_store_20250915143036\nGETSIMN 4 WITH ["Jordan One"] USING cosinesimilarity IN ai_store_20250915143036\nLISTSTORES\n'})}),"\n",(0,t.jsxs)(n.p,{children:["These queries ",(0,t.jsx)(n.strong,{children:"create stores"}),", ",(0,t.jsx)(n.strong,{children:"insert data"}),", and ",(0,t.jsx)(n.strong,{children:"query similarity"})," the operations we\u2019ll automate in code."]}),"\n",(0,t.jsx)(n.h2,{id:"program-implementing-the-queries",children:"Program Implementing the Queries"}),"\n",(0,t.jsxs)(s,{children:[(0,t.jsx)("summary",{children:"Click to Expand Code"}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'import asyncio \nimport logging\nfrom datetime import datetime\nfrom grpclib.client import Channel\n\n\nfrom ahnlich_client_py.grpc.services.ai_service import AiServiceStub\nfrom ahnlich_client_py.grpc.services.db_service import DbServiceStub\nfrom ahnlich_client_py.grpc.ai import query as ai_query\nfrom ahnlich_client_py.grpc.ai import preprocess\nfrom ahnlich_client_py.grpc.algorithm import algorithms\nfrom ahnlich_client_py.grpc import keyval, metadata\nfrom ahnlich_client_py.grpc.db import query as db_query\n\n\nfrom opentelemetry import trace\nfrom opentelemetry.sdk.resources import Resource\nfrom opentelemetry.sdk.trace import TracerProvider\nfrom opentelemetry.sdk.trace.export import BatchSpanProcessor\nfrom opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter\n\n\n# -------------------------\n# Logging Setup\n# -------------------------\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger("tracing")\n\n\n# -------------------------\n# OpenTelemetry Setup\n# -------------------------\nresource = Resource.create({"service.name": "tracing-client"})\nprovider = TracerProvider(resource=resource)\nexporter = OTLPSpanExporter(endpoint="http://localhost:4317", insecure=True)\nprovider.add_span_processor(BatchSpanProcessor(exporter))\ntrace.set_tracer_provider(provider)\ntracer = trace.get_tracer(__name__)\n\n\n# -------------------------\n# Generate unique store names\n# -------------------------\ntimestamp = datetime.now().strftime("%Y%m%d%H%M%S")\ndb_store_name = f"db_store_{timestamp}"\nai_store_name = f"ai_store_{timestamp}"\n\n\n# -------------------------\n# Main async workflow\n# -------------------------\nasync def main():\n   async with Channel(host="127.0.0.1", port=1369) as db_channel, \\\n              Channel(host="127.0.0.1", port=1370) as ai_channel:\n\n\n       db_client = DbServiceStub(db_channel)\n       ai_client = AiServiceStub(ai_channel)\n\n\n       text = "This is the life of Alice"\n       trace_id = f"similarity-workflow-{timestamp}"\n       logger.info("[tracing] started similarity-workflow, trace_id=%s", trace_id)\n\n\n       # -------------------------\n       # Create DB Store\n       # -------------------------\n       with tracer.start_as_current_span("db.create_store"):\n           try:\n               create_db_req = db_query.CreateStore(\n                   store=db_store_name,\n                   dimension=512,\n                   create_predicates=[],\n                   non_linear_indices=[],\n                   error_if_exists=False\n               )\n               await db_client.create_store(create_db_req)\n               logger.info("DB Store created: %s", db_store_name)\n           except Exception as e:\n               logger.error("Failed to create DB store: %s", e)\n\n\n       # -------------------------\n       # Insert DB Entry\n       # -------------------------\n       with tracer.start_as_current_span("db.insert_entry"):\n           try:\n               vector = [0.1] * 512  # List of floats\n               entry = keyval.DbStoreEntry(\n                   key=keyval.StoreKey(key=vector),\n                   value=keyval.StoreValue(\n                       value={"text": metadata.MetadataValue(raw_string=text)}\n                   )\n               )\n               set_req = db_query.Set(store=db_store_name, inputs=[entry])\n               await db_client.set(set_req)\n               logger.info("Inserted entry into DB store")\n           except Exception as e:\n               logger.error("Failed to insert DB entries: %s", e)\n\n\n       # -------------------------\n       # Create AI Store\n       # -------------------------\n       with tracer.start_as_current_span("ai.create_store"):\n           try:\n               from ahnlich_client_py.grpc.ai.models import AiModel\n\n\n               create_ai_req = ai_query.CreateStore(\n                   store=ai_store_name,\n                   query_model=AiModel.ALL_MINI_LM_L6_V2,\n                   index_model=AiModel.ALL_MINI_LM_L6_V2,\n                   predicates=["author", "category"],\n                   error_if_exists=False,\n                   store_original=True\n               )\n               await ai_client.create_store(create_ai_req)\n               logger.info("AI Store created: %s", ai_store_name)\n           except Exception as e:\n               logger.error("Failed to create AI store: %s", e)\n\n\n       # -------------------------\n       # Insert AI Entries\n       # -------------------------\n       with tracer.start_as_current_span("ai.insert_entries"):\n           try:\n               ai_entries = [\n                   keyval.AiStoreEntry(\n                       key=keyval.StoreInput(raw_string="Jordan One"),\n                       value=keyval.StoreValue(\n                           value={"brand": metadata.MetadataValue(raw_string="Nike")}\n                       ),\n                   ),\n                   keyval.AiStoreEntry(\n                       key=keyval.StoreInput(raw_string="Yeezey"),\n                       value=keyval.StoreValue(\n                           value={"brand": metadata.MetadataValue(raw_string="Adidas")}\n                       ),\n                   )\n               ]\n               set_ai_req = ai_query.Set(\n                   store=ai_store_name,\n                   inputs=ai_entries,\n                   preprocess_action=preprocess.PreprocessAction.NoPreprocessing\n               )\n               await ai_client.set(set_ai_req)\n               logger.info("Inserted entries into AI store")\n           except Exception as e:\n               logger.error("Failed to insert AI entries: %s", e)\n\n\n       # -------------------------\n       # AI Similarity Query\n       # -------------------------\n       with tracer.start_as_current_span("ai.get_sim_n"):\n           try:\n               search_input = keyval.StoreInput(raw_string="Jordan One")\n               ai_sim_req = ai_query.GetSimN(\n                   store=ai_store_name,\n                   search_input=search_input,\n                   closest_n=4,\n                   algorithm=algorithms.Algorithm.CosineSimilarity,\n                   preprocess_action=preprocess.PreprocessAction.NoPreprocessing\n               )\n               ai_response = await ai_client.get_sim_n(ai_sim_req)\n               logger.info("AI similarity response received")\n               print(ai_response)\n           except Exception as e:\n               logger.error("AI similarity call failed: %s", e)\n\n\n       # -------------------------\n       # List DB Stores\n       # -------------------------\n       with tracer.start_as_current_span("db.list_stores"):\n           try:\n               stores = await db_client.list_stores(db_query.ListStores())\n               logger.info("DB Stores: %s", stores)\n           except Exception as e:\n               logger.error("Failed to list DB stores: %s", e)\n\n\n       # -------------------------\n       #  List AI Stores\n       # -------------------------\n       with tracer.start_as_current_span("ai.list_stores"):\n           try:\n               ai_stores = await ai_client.list_stores(ai_query.ListStores())\n               logger.info("AI Stores: %s", ai_stores)\n           except Exception as e:\n               logger.error("Failed to list AI stores: %s", e)\n\n\n\n\nif __name__ == "__main__":\n   asyncio.run(main())\n\n'})})]}),"\n",(0,t.jsx)(n.h2,{id:"code-explanation",children:"Code Explanation"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"OpenTelemetry Setup"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Creates a ",(0,t.jsx)(n.strong,{children:"tracer provider"}),", sets ",(0,t.jsx)(n.strong,{children:"service name"})," as ",(0,t.jsx)(n.code,{children:"tracing-client"}),", and exports spans to ",(0,t.jsx)(n.strong,{children:"Jaeger via OTLP gRPC"}),"."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Unique Store Names"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Ensures every workflow run has new DB and AI stores using a timestamp."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"DB Operations"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"CreateStore"})," \u2192 Creates a vector store."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"Set"})," \u2192 Inserts a numeric vector with metadata."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"ListStores"})," \u2192 Retrieves all DB stores."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"AI Operations"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"CreateStore"})," \u2192 Creates an embedding AI store."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"Set"})," \u2192 Inserts text entries with metadata."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"GetSimN"})," \u2192 Queries the AI store for closest matches using cosine similarity."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"ListStores"})," \u2192 Retrieves all AI stores."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Tracing Spans"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Every operation wrapped in ",(0,t.jsx)(n.code,{children:"tracer.start_as_current_span()"})," generates a ",(0,t.jsx)(n.strong,{children:"trace span in Jaeger"}),", giving ",(0,t.jsx)(n.strong,{children:"start/end time"}),", ",(0,t.jsx)(n.strong,{children:"logs"}),", and ",(0,t.jsx)(n.strong,{children:"events"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"viewing-spans-in-jaeger",children:"Viewing Spans in Jaeger"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Open ",(0,t.jsx)(n.strong,{children:"Jaeger UI"}),": ",(0,t.jsx)(n.a,{href:"http://localhost:16686",children:"http://localhost:16686"})]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["In ",(0,t.jsx)(n.strong,{children:"Service"}),", select ",(0,t.jsx)(n.code,{children:"tracing-client"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["Click ",(0,t.jsx)(n.strong,{children:"Find Traces"}),"  You\u2019ll see spans for each step:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"db.create_store"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"ai.create_store"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"ai.get_sim_n"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"db.list_stores"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"ai.list_stores"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Expand each span to see:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Start/end times"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.strong,{children:"Logs and events"})}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Metadata from the operation"}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Example spans captured from a run might include ",(0,t.jsx)(n.code,{children:"DB Store created: db_store_20250915143036"})," and ",(0,t.jsx)(n.code,{children:"AI similarity"})," response received."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.img,{alt:"Screenshot 1",src:r(14753).A+"",width:"833",height:"516"}),"\n",(0,t.jsx)(n.img,{alt:"Screenshot 2",src:r(57322).A+"",width:"837",height:"570"}),"\n",(0,t.jsx)(n.img,{alt:"Screenshot 3",src:r(89235).A+"",width:"849",height:"504"}),"\n",(0,t.jsx)(n.img,{alt:"Screenshot 4",src:r(91836).A+"",width:"849",height:"504"}),"\n",(0,t.jsx)(n.img,{alt:"Screenshot 5",src:r(27749).A+"",width:"883",height:"566"}),"\n",(0,t.jsx)(n.img,{alt:"Screenshot 6",src:r(16270).A+"",width:"886",height:"359"}),"\n",(0,t.jsx)(n.img,{alt:"Screenshot 7",src:r(15767).A+"",width:"868",height:"559"}),"\n",(0,t.jsx)(n.img,{alt:"Screenshot 8",src:r(99408).A+"",width:"767",height:"562"})]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},89235:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/images/jaeger-3-f43d968bac85200fb8239b719099d0e1.png"},91836:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/images/jaeger-4-f43d968bac85200fb8239b719099d0e1.png"},99408:(e,n,r)=>{r.d(n,{A:()=>s});const s=r.p+"assets/images/jaeger-8-7edb5ab434186c2487b29b1377e533af.png"}}]);