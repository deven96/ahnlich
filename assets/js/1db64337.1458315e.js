"use strict";(self.webpackChunkahnlich_web=self.webpackChunkahnlich_web||[]).push([[8413],{2883:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>a,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"overview","title":"Overview","description":"\u2728 Ahnlich is a modern, in-memory vector database paired with a smart AI proxy layer, designed to simplify the use of semantic embeddings for developers and AI builders with zero external dependencies.","source":"@site/docs/overview.md","sourceDirName":".","slug":"/overview","permalink":"/docs/overview","draft":false,"unlisted":false,"editUrl":"https://github.com/deven96/ahnlich/tree/main/web/ahnlich-web/docs/overview.md","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"title":"Overview","sidebar_position":10},"sidebar":"docsSidebar","next":{"title":"\ud83d\udce6 Installation","permalink":"/docs/getting-started/installation"}}');var r=i(4848),t=i(8453);const l={title:"Overview",sidebar_position:10},o="Overview",a={},d=[{value:"\ud83e\udde0 What is Ahnlich?",id:"-what-is-ahnlich",level:2},{value:"\ud83d\ude80 In-Memory Vector Database",id:"-in-memory-vector-database",level:3},{value:"\ud83e\udd16 AI Proxy Layer",id:"-ai-proxy-layer",level:3},{value:"\ud83d\udcda Vector Databases: Explained",id:"-vector-databases-explained",level:2},{value:"\ud83c\udf1f Product Pillars",id:"-product-pillars",level:2},{value:"\ud83d\udee0\ufe0f Use Cases &amp; Applications",id:"\ufe0f-use-cases--applications",level:2},{value:"\ud83d\udc65 Who Is It For?",id:"-who-is-it-for",level:2},{value:"\u2705 Quick Links",id:"-quick-links",level:2}];function c(e){const n={a:"a",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"overview",children:"Overview"})}),"\n",(0,r.jsxs)(n.p,{children:["\u2728 ",(0,r.jsx)(n.strong,{children:"Ahnlich"})," is a modern, in-memory ",(0,r.jsx)(n.strong,{children:"vector database"})," paired with a smart ",(0,r.jsx)(n.strong,{children:"AI proxy layer"}),", designed to simplify the use of semantic embeddings for developers and AI builders with zero external dependencies."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-what-is-ahnlich",children:"\ud83e\udde0 What is Ahnlich?"}),"\n",(0,r.jsx)(n.h3,{id:"-in-memory-vector-database",children:"\ud83d\ude80 In-Memory Vector Database"}),"\n",(0,r.jsx)(n.p,{children:"Ahnlich provides an ultra-fast, RAM-resident vector store with:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pure linear similarity search"})," using ",(0,r.jsx)(n.strong,{children:"Cosine Similarity"}),", ",(0,r.jsx)(n.strong,{children:"Euclidean Distance (L2)"}),", or ",(0,r.jsx)(n.strong,{children:"Dot Product"})," to retrieve semantically similar vectors\u2014ideal for small-to-medium data sets and prototyping."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Dynamic update support"}),"\u2014add, update, or delete vectors on-the-fly without full index rebuilds."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Metadata support"})," (tags, categories, timestamps), allowing ",(0,r.jsx)(n.strong,{children:"hybrid filtering"})," (e.g. \u201csimilarity + metadata condition\u201d) for refined retrieval."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Zero external service dependency"}),"\u2014runs as a self-contained binary with no server or cluster required."]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"(Support for approximate methods like HNSW or LSH is on the roadmap.)"})}),"\n",(0,r.jsx)(n.h3,{id:"-ai-proxy-layer",children:"\ud83e\udd16 AI Proxy Layer"}),"\n",(0,r.jsx)(n.p,{children:"Built-in intelligent middleware for embedding-based AI workflows:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Accepts ",(0,r.jsx)(n.em,{children:"raw text inputs"}),", forwards to your preferred embedding provider or LLM, and ",(0,r.jsx)(n.strong,{children:"caches embeddings locally"})," to reduce redundant API calls."]}),"\n",(0,r.jsxs)(n.li,{children:["Implements ",(0,r.jsx)(n.strong,{children:"Retrieval-Augmented Generation (RAG)"})," workflows\u2014pull relevant document embeddings, optionally compose prompts, and send to LLMs."]}),"\n",(0,r.jsxs)(n.li,{children:["Tracks ",(0,r.jsx)(n.strong,{children:"usage metadata"})," (timestamps, model IDs, query context) for observability and tuning."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Together, these allow building ",(0,r.jsx)(n.strong,{children:"AI-aware applications"})," quickly without managing separate services."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-vector-databases-explained",children:"\ud83d\udcda Vector Databases: Explained"}),"\n",(0,r.jsxs)(n.p,{children:["A vector database is purpose-built for ",(0,r.jsx)(n.strong,{children:"semantic similarity workloads"}),"\u2014it transforms raw content (text/images) into ",(0,r.jsx)(n.strong,{children:"high-dimensional numeric vectors"})," alongside their metadata, then stores and retrieves them efficiently for meaning-based search."]}),"\n",(0,r.jsxs)(n.p,{children:["While classic nearest-neighbor search relies on expensive all-pairs or linear scans, modern systems often use ",(0,r.jsx)(n.strong,{children:"index structures"})," for approximate methods like HNSW, LSH, or Product Quantization\u2014trading off precision for speed."]}),"\n",(0,r.jsxs)(n.p,{children:["Ahnlich currently supports only ",(0,r.jsx)(n.strong,{children:"exact, linear similarity search"})," over updated vectors using these distance metrics:"]}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Metric"}),(0,r.jsx)(n.th,{children:"Description"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Cosine"})}),(0,r.jsxs)(n.td,{children:["Measures the ",(0,r.jsx)(n.strong,{children:"angle"})," between vectors (direction)"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Euclidean (L2)"})}),(0,r.jsxs)(n.td,{children:["Computes the straight-line ",(0,r.jsx)(n.strong,{children:"distance"})," in vector space"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:(0,r.jsx)(n.strong,{children:"Dot Product"})}),(0,r.jsxs)(n.td,{children:["Combines ",(0,r.jsx)(n.strong,{children:"magnitude + alignment"}),", fast when pre-normalized"]})]})]})]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"(Note: Euclidean/L2, cosine, and dot-product are closely related at constant scale.)"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-product-pillars",children:"\ud83c\udf1f Product Pillars"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lightning-fast embedding store"})," in pure memory, optimized for low-latency lookups."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Hybrid similarity filtering"}),", combining semantic distance with metadata constraints."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"AI-aware proxy engine"}),", serving as a bridge between your app, embeddings, and LLMs."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lightweight, deployment-free integration"}),"\u2014no server, cluster, or managed runtime needed."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Developer-first experience"}),", focusing on speed and simplicity without sacrificing flexibility."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"\ufe0f-use-cases--applications",children:"\ud83d\udee0\ufe0f Use Cases & Applications"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Document Search & FAQ Retrieval"})," \u2013 Store docs, Markdown content, or product specs as embeddings. Ahnlich retrieves them semantically using cosine/L2, refined by filters like categories or tags."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"RAG Chat Memory"})," \u2013 Maintain conversational context via embeddings. On each turn, fetch the most relevant past chunks to enrich LLM prompts."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Semantic Retrieval of Logs & Snippets"})," \u2013 Developer tooling to find code or log entries that are meaningfully similar\u2014not just keyword matches."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Recommendation & Similarity Engines"})," \u2013 Turn items (users, documents, products) into vectors; run coherent similarity + metadata filters (e.g. user locale, rating)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Edge & Prototype AI Apps"})," \u2013 No cloud dependency, minimal footprint\u2014ideal for prototyping, embedded deployments, or local development."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-who-is-it-for",children:"\ud83d\udc65 Who Is It For?"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Developers and AI/Python engineers"})," building embedding-based logic or semantic apps."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Startups & MVP coders"})," needing fast local experimentation without infrastructure overhead."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Data scientists / Machine learning practitioners"})," benchmarking embedding behavior or clustering."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Educators & technical writers"})," wanting clear vector-search based examples or teaching tools."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"-quick-links",children:"\u2705 Quick Links"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/getting-started/",children:"Getting Started Guide"})}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"Note: \u201cRetrieval-Augmented Generation\u201d (RAG) is a well-established pattern for combining embedding retrieval with LLM responses."})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"Break down of supported similarity metrics and their behavior is adapted from standard docs on vector searches."})})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>l,x:()=>o});var s=i(6540);const r={},t=s.createContext(r);function l(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:l(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);