"use strict";(self.webpackChunkahnlich_web=self.webpackChunkahnlich_web||[]).push([[752],{25860:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>c,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>a});const r=JSON.parse('{"id":"client-libraries/python/request-ai/set","title":"Set","description":"The Set request is used to insert or update entries inside an AI-powered store.","source":"@site/docs/client-libraries/python/request-ai/set.md","sourceDirName":"client-libraries/python/request-ai","slug":"/client-libraries/python/request-ai/set","permalink":"/docs/client-libraries/python/request-ai/set","draft":false,"unlisted":false,"editUrl":"https://github.com/deven96/ahnlich/tree/main/web/ahnlich-web/docs/client-libraries/python/request-ai/set.md","tags":[],"version":"current","frontMatter":{"title":"Set"},"sidebar":"docsSidebar","previous":{"title":"Create Store","permalink":"/docs/client-libraries/python/request-ai/create-store"},"next":{"title":"GetSimN","permalink":"/docs/client-libraries/python/request-ai/get-simn"}}');var s=t(74848),i=t(28453);const o={title:"Set"},c="Set",l={},a=[{value:"Key Notes",id:"key-notes",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"set",children:"Set"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"Set"})," request is used to ",(0,s.jsx)(n.strong,{children:"insert or update entries"})," inside an AI-powered store."]}),"\n",(0,s.jsxs)(n.p,{children:["Unlike the DB client (which expects raw vectors), the AI client allows you to store ",(0,s.jsx)(n.strong,{children:"raw strings or other inputs"})," directly.\nThe AI service will automatically ",(0,s.jsx)(n.strong,{children:"embed these inputs"})," using the store\u2019s configured models."]}),"\n",(0,s.jsxs)(t,{children:[(0,s.jsx)("summary",{children:"Click to expand source code"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:'import asyncio\nfrom grpclib.client import Channel\nfrom ahnlich_client_py.grpc.services.ai_service import AiServiceStub\nfrom ahnlich_client_py.grpc.ai import query as ai_query\nfrom ahnlich_client_py.grpc import keyval, metadata\nfrom ahnlich_client_py.grpc.ai import preprocess\n\n\nasync def sets():\n  async with Channel(host="127.0.0.1", port=1370) as channel:\n      client = AiServiceStub(channel)\n      response = await client.set(\n          ai_query.Set(\n              store="test store",\n              inputs=[\n                  keyval.AiStoreEntry(\n                      key=keyval.StoreInput(raw_string="Jordan One"),\n                      value=keyval.StoreValue(\n                          value={"brand": metadata.MetadataValue(raw_string="Nike")}\n                      ),\n                  ),\n                  keyval.AiStoreEntry(\n                      key=keyval.StoreInput(raw_string="Yeezey"),\n                      value=keyval.StoreValue(\n                          value={"brand": metadata.MetadataValue(raw_string="Adidas")}\n                      ),\n                  )\n              ],\n              preprocess_action=preprocess.PreprocessAction.NoPreprocessing,\n              execution_provider=None  # Optional: e.g., ExecutionProvider.CUDA for GPU acceleration\n          )\n      )\n      print(response) #Set(upsert=StoreUpsert(inserted=2))\n\n\nif __name__ == "__main__":\n  asyncio.run(sets())\n\n'})})]}),"\n",(0,s.jsx)(n.h2,{id:"key-notes",children:"Key Notes"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"inputs"})})," - list of entries to be stored."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Each entry has:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"key"})}),' - the raw input (e.g., "Jordan One") that gets embedded by the AI model.']}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"value"})})," - metadata associated with the key (e.g., ",(0,s.jsx)(n.code,{children:'"brand": Nike'}),")."]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"preprocess_action"})})," - defines how inputs are preprocessed before embedding."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"NoPreprocessing"})," - raw text is passed as-is to the embedding model."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"Other preprocessing options (like normalization or tokenization) can be applied depending on the use case."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.code,{children:"execution_provider"})})," - Optional hardware acceleration for model inference (e.g., ",(0,s.jsx)(n.code,{children:"CUDA"}),", ",(0,s.jsx)(n.code,{children:"TensorRT"}),", ",(0,s.jsx)(n.code,{children:"CoreML"}),"). Set to ",(0,s.jsx)(n.code,{children:"None"})," for default CPU execution."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Response"})," \u2192 returns counts of inserted vs. updated items (",(0,s.jsx)(n.code,{children:"upsert counts"}),")."]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},28453:(e,n,t)=>{t.d(n,{R:()=>o,x:()=>c});var r=t(96540);const s={},i=r.createContext(s);function o(e){const n=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(i.Provider,{value:n},e.children)}}}]);