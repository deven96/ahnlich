"use strict";(self.webpackChunkahnlich_web=self.webpackChunkahnlich_web||[]).push([[2443],{936:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"architecture","title":"\ud83c\udfdb\ufe0f Architecture","description":"Status: Alpha / testing \u2013 subject to breaking changes.","source":"@site/docs/architecture.md","sourceDirName":".","slug":"/architecture","permalink":"/docs/architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/deven96/ahnlich/tree/main/web/ahnlich-web/docs/architecture.md","tags":[],"version":"current","sidebarPosition":60,"frontMatter":{"title":"\ud83c\udfdb\ufe0f Architecture","sidebar_position":60},"sidebar":"docsSidebar","previous":{"title":"\u26a1Ahnlich in production","permalink":"/docs/ahnlich-in-production/"},"next":{"title":"\ud83c\udf0d Community","permalink":"/docs/community"}}');var t=r(4848),s=r(8453);const l={title:"\ud83c\udfdb\ufe0f Architecture",sidebar_position:60},d="Ahnlich Architecture V2",c={},o=[{value:"\ud83d\udce6 1.  High\u2011Level Design",id:"-1--highlevel-design",level:2},{value:"Analogy to Kafka",id:"analogy-to-kafka",level:3},{value:"2. Key Components",id:"2-key-components",level:2},{value:"2.1  <code>ahnlich\u2011ai</code> \u2013 Intelligence Layer",id:"21--ahnlichai--intelligence-layer",level:3},{value:"2.2 <code>ahnlich\u2011db</code> \u2013 Vector Store Layer",id:"22-ahnlichdb--vector-store-layer",level:3},{value:"3.  Data Flow",id:"3--data-flow",level:2},{value:"3.1  Indexing (Write) Path",id:"31--indexing-write-path",level:3},{value:"3.2  Similarity Query Path",id:"32--similarity-query-path",level:3},{value:"3.3  Direct DB Access",id:"33--direct-db-access",level:3},{value:"4  Persistence &amp; Durability",id:"4--persistence--durability",level:2},{value:"5. Scaling &amp; Deployment Topologies",id:"5-scaling--deployment-topologies",level:2},{value:"6.  Observability",id:"6--observability",level:2},{value:"7.  Extensibility",id:"7--extensibility",level:2},{value:"8.  Security Considerations",id:"8--security-considerations",level:2},{value:"9.  Limitations (July 2025)",id:"9--limitations-july-2025",level:2},{value:"\ud83d\udd0d Summary",id:"-summary",level:2}];function a(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",mermaid:"mermaid",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"ahnlich-architecture-v2",children:"Ahnlich Architecture V2"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Status"}),": ",(0,t.jsx)(n.em,{children:"Alpha / testing \u2013 subject to breaking changes."}),"**"]}),"\n",(0,t.jsx)(n.p,{children:"Ahnlich is split into two independent, network\u2011accessible services that work in tandem:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["ahnlich\u2011ai \u2013 ",(0,t.jsx)(n.strong,{children:"the Intelligence Layer"})]}),"\n",(0,t.jsxs)(n.li,{children:["ahnlich\u2011db \u2013 ",(0,t.jsx)(n.strong,{children:"the Vector Store Layer"})]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Clients can speak to either layer through gRPC/HTTP or the bundled CLI/SDKs. The AI layer adds automated embedding and model management on top of the raw vector store exposed by the DB layer."}),"\n",(0,t.jsx)(n.h2,{id:"-1--highlevel-design",children:"\ud83d\udce6 1.  High\u2011Level Design"}),"\n",(0,t.jsx)(n.mermaid,{value:'flowchart TD\n\n  subgraph ai [ahnlich\u2011ai]\n\n    direction TB\n\n    AIClient["AI Client"]\n\n    StoreHandlerAI["Store Handler"]\n\n    StoreA_AI["Store A"]\n\n    ModelNode["Index Model \u2192 Model B<br/>Query Model \u2192 Model A<br/>Pre\u2011process"]\n\n    PersistenceAI[(Persistence)]\n\n    AIClient --\x3e |"original + metadata"| StoreHandlerAI\n\n    StoreHandlerAI --\x3e StoreA_AI\n\n    StoreA_AI --\x3e ModelNode\n\n    ModelNode -.-> PersistenceAI\n\n  end\n\n  subgraph db [ahnlich\u2011db]\n\n    direction TB\n\n    DBClient["DB Client"]\n\n    StoreHandlerDB["Store Handler"]\n\n    StoreA_DB["Store A"]\n\n    PersistenceDB[(Persistence)]\n\n    DBClient --\x3e |"DB query"| StoreHandlerDB\n\n    StoreHandlerDB --\x3e StoreA_DB\n\n    StoreA_DB -.-> PersistenceDB\n\n  end\n\n\n  %% Inter\u2011service calls\n\n  StoreHandlerAI -.-> |"Set: vector + metadata"| StoreHandlerDB\n\n  StoreHandlerAI -.-> |"GetSimN: vector"| StoreHandlerDB\n\n  StoreHandlerDB -.-> |"Top\u2011N results"| StoreHandlerAI\n'}),"\n",(0,t.jsx)(n.h3,{id:"analogy-to-kafka",children:"Analogy to Kafka"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Kafka"}),(0,t.jsx)(n.th,{children:"Ahnlich"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Producer"})}),(0,t.jsx)(n.td,{children:"AI Client / DB Client"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Broker"})}),(0,t.jsx)(n.td,{children:"ahnlich\u2011ai & ahnlich\u2011db services"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Topic / Partition"})}),(0,t.jsx)(n.td,{children:"Store (logical namespace)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Message"})}),(0,t.jsx)(n.td,{children:"Vector + metadata"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Consumer"})}),(0,t.jsx)(n.td,{children:"Client fetching GetSimN"})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"2-key-components",children:"2. Key Components"}),"\n",(0,t.jsxs)(n.h3,{id:"21--ahnlichai--intelligence-layer",children:["2.1  ",(0,t.jsx)(n.code,{children:"ahnlich\u2011ai"})," \u2013 Intelligence Layer"]}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Sub\u2011component"}),(0,t.jsx)(n.th,{children:"Responsibility"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"AI Client API"})}),(0,t.jsx)(n.td,{children:"External gRPC/HTTP endpoints \u2013 accepts raw documents (text, images\u2026) & metadata."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Store Handler"})}),(0,t.jsx)(n.td,{children:"Maps incoming requests to a Store; maintains per\u2011store configuration (models, preprocess pipeline)."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Store"})}),(0,t.jsx)(n.td,{children:"Logical namespace. Each holds a pair of ONNX models (Index & Query) plus preprocessing logic."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Model Node"})}),(0,t.jsx)(n.td,{children:"Executes preprocessing \u2192 model inference \u2192 produces embedding."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Optional Persistence"})}),(0,t.jsx)(n.td,{children:"Periodic snapshots of store metadata & model cache to disk."})]})]})]}),"\n",(0,t.jsxs)(n.h3,{id:"22-ahnlichdb--vector-store-layer",children:["2.2 ",(0,t.jsx)(n.code,{children:"ahnlich\u2011db"})," \u2013 Vector Store Layer"]}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Sub\u2011component"}),(0,t.jsx)(n.th,{children:"Responsibility"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"DB Client API"})}),(0,t.jsx)(n.td,{children:"Accepts vector\u2011level commands: SET, GETSIMN, CREATESTORE, etc."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Store Handler"})}),(0,t.jsx)(n.td,{children:"Routes to correct Store; enforces isolation; coordinates concurrent reads/writes."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Store (Vector Index)"})}),(0,t.jsx)(n.td,{children:"In\u2011memory index (brute\u2011force or KD\u2011Tree) plus metadata map. Supports cosine & Euclidean similarity."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Filter Engine"})}),(0,t.jsx)(n.td,{children:"Applies boolean predicates on metadata during query."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Optional Persistence"})}),(0,t.jsx)(n.td,{children:"Snapshots vectors & metadata to on\u2011disk binary file for warm restarts."})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"3--data-flow",children:"3.  Data Flow"}),"\n",(0,t.jsx)(n.h3,{id:"31--indexing-write-path",children:"3.1  Indexing (Write) Path"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Client"})," \u279c AI Layer \u2013 Sends raw document + metadata."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Preprocessing & Embedding"})," \u2013 AI layer cleans input, runs Index Model to yield vector."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AI \u279c DB"})," \u2013 Issues SET carrying vector & metadata."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"DB Store"})," \u2013 Writes vector into index, stores metadata."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"32--similarity-query-path",children:"3.2  Similarity Query Path"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Client \u279c AI Layer"})," \u2013 Provides search text/image."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Embedding"})," \u2013 AI layer runs Query Model to create search vector."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AI \u279c DB (GETSIMN)"})," \u2013 Vector + algorithm + optional predicate."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"DB"})," \u2013 Computes distance, applies metadata filter, returns Top\u2011N IDs & scores."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AI Layer"})," \u2013 (Optional) post\u2011processes or joins additional metadata before responding to client."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"33--direct-db-access",children:"3.3  Direct DB Access"}),"\n",(0,t.jsx)(n.p,{children:"Advanced users can bypass AI and push pre\u2011computed vectors directly into ahnlich\u2011db for maximum control."}),"\n",(0,t.jsx)(n.h2,{id:"4--persistence--durability",children:"4  Persistence & Durability"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Opt\u2011in via"})," --enable-persistence."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Snapshot interval"})," configurable (--persistence-interval, default 300 s)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"DB"})," writes a flat binary file; ",(0,t.jsx)(n.strong,{children:"AI"})," persists model cache & store manifests."]}),"\n",(0,t.jsx)(n.li,{children:"On startup each service checks for the snapshot file and hydrates memory before accepting traffic."}),"\n",(0,t.jsx)(n.li,{children:"No replication yet; Ahnlich currently targets single\u2011node or shared\u2011nothing sharded deployments."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"5-scaling--deployment-topologies",children:"5. Scaling & Deployment Topologies"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Pattern"}),(0,t.jsx)(n.th,{children:"How it works"}),(0,t.jsx)(n.th,{children:"When to use"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Single\u2011Node"})}),(0,t.jsxs)(n.td,{children:["One ",(0,t.jsx)(n.code,{children:"ahnlich\u2011ai"})," & one ",(0,t.jsx)(n.code,{children:"ahnlich\u2011db"})," container (shown in README Compose)."]}),(0,t.jsx)(n.td,{children:"Prototyping, local dev."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Vertical Scaling"})}),(0,t.jsx)(n.td,{children:"Give DB more RAM/CPU; mount NVIDIA GPU for AI layer."}),(0,t.jsx)(n.td,{children:"Medium workloads where a single node still fits in memory."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Store\u2011Level Sharding"})}),(0,t.jsx)(n.td,{children:"Run multiple DB instances, each owning a subset of Stores; fronted by one AI layer."}),(0,t.jsx)(n.td,{children:"Multi\u2011tenant SaaS or very large corpora."})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Function Sharding"})}),(0,t.jsx)(n.td,{children:"Isolate heavy NLP image pipelines by model type: one AI instance per model group."}),(0,t.jsx)(n.td,{children:"Heterogeneous workloads, GPU scheduling."})]})]})]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Roadmap"}),": cluster\u2011wide replication & consistent hashing for transparent sharding."]}),"\n",(0,t.jsx)(n.h2,{id:"6--observability",children:"6.  Observability"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Both services instrumented with ",(0,t.jsx)(n.strong,{children:"OpenTelemetry"}),"; enable with --enable-tracing and send spans to Jaeger, Prometheus, etc."]}),"\n",(0,t.jsx)(n.li,{children:"Internal metrics: query latency, index size, RAM usage, model inference time."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"7--extensibility",children:"7.  Extensibility"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Add a new similarity metric"})," \u2013 implement SimAlgorithm trait in ahnlich\u2011db."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Bring your own model"})," \u2013 point ahnlich\u2011ai to an ONNX file or HuggingFace repo via --supported-models."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Custom predicates"})," \u2013 extend the predicate DSL to support regex or full\u2011text."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"8--security-considerations",children:"8.  Security Considerations"}),"\n",(0,t.jsx)(n.p,{children:"Currently no built\u2011in auth. Recommend placing behind an API gateway or reverse proxy that enforces:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"JWT / OAuth 2 bearer tokens."}),"\n",(0,t.jsx)(n.li,{children:"Mutual TLS between AI \u21c4 DB if running across hosts."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"9--limitations-july-2025",children:"9.  Limitations (July 2025)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"No distributed consensus \u2013 durability limited to local snapshots."}),"\n",(0,t.jsx)(n.li,{children:"Single\u2011writer per Store lock may become a bottleneck under heavy concurrent writes."}),"\n",(0,t.jsx)(n.li,{children:"Model hot\u2011swap requires store recreation."}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"-summary",children:"\ud83d\udd0d Summary"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:"Ahnlich decouples vector intelligence"})," (embedding generation, model lifecycle) from vector persistence & retrieval. This split allows you to scale and tune each layer independently while keeping a simple mental model\u2014much like Kafka separates producers, brokers, and consumers around an immutable log."]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>d});var i=r(6540);const t={},s=i.createContext(t);function l(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);