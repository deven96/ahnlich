"use strict";(self.webpackChunkahnlich_web=self.webpackChunkahnlich_web||[]).push([[1138],{23333:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>o});const i=JSON.parse('{"id":"client-libraries/python/request-ai/request-ai","title":"Request AI","description":"The Ahnlich AI Client provides intelligent services that extend the capabilities of the DB client.","source":"@site/docs/client-libraries/python/request-ai/request-ai.md","sourceDirName":"client-libraries/python/request-ai","slug":"/client-libraries/python/request-ai/","permalink":"/docs/client-libraries/python/request-ai/","draft":false,"unlisted":false,"editUrl":"https://github.com/deven96/ahnlich/tree/main/web/ahnlich-web/docs/client-libraries/python/request-ai/request-ai.md","tags":[],"version":"current","frontMatter":{"title":"Request AI","sidebar_posiiton":3},"sidebar":"docsSidebar","previous":{"title":"Delete Predicate","permalink":"/docs/client-libraries/python/request-db/delete-predicate"},"next":{"title":"Ping","permalink":"/docs/client-libraries/python/request-ai/ping"}}');var s=r(74848),t=r(28453);const l={title:"Request AI",sidebar_posiiton:3},a="Request AI",d={},o=[{value:"Key Features",id:"key-features",level:2},{value:"Supported Raw Inputs",id:"supported-raw-inputs",level:2},{value:"Models",id:"models",level:2},{value:"Create a Store",id:"create-a-store",level:2},{value:"Insert Raw Input",id:"insert-raw-input",level:2},{value:"Query with Raw Input",id:"query-with-raw-input",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components},{Details:r}=n;return r||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"request-ai",children:"Request AI"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.strong,{children:"Ahnlich AI Client"})," provides intelligent services that extend the capabilities of the DB client.\nWhile the DB client is optimized for storing vectors, managing stores, and retrieving them efficiently, the AI client is responsible for ",(0,s.jsx)(n.strong,{children:"embedding generation"}),", ",(0,s.jsx)(n.strong,{children:"preprocessing"}),", and ",(0,s.jsx)(n.strong,{children:"querying using raw inputs"}),"."]}),"\n",(0,s.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Raw input support"}),": Accepts text or images as input."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Embedding generation"}),": Automatically transforms raw input into embeddings using AI models."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"AI proxy"}),": Communicates with Ahnlich-DB to persist embeddings and metadata."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Query with raw input"}),": No need to manually generate vectors just pass text or images."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Flexible models"}),": Choose different models for indexing vs querying."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Metadata integration"}),": Store structured information alongside embeddings."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Bulk requests"}),": Chain multiple operations (",(0,s.jsx)(n.code,{children:"ping"}),", ",(0,s.jsx)(n.code,{children:"list_stores"}),", etc.) for efficiency."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"supported-raw-inputs",children:"Supported Raw Inputs"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Text"})," - sentences, titles, product descriptions, etc."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Images"})," - passed as binary (",(0,s.jsx)(n.code,{children:"u8"})," list)."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Mixed stores"})," depending on the selected AI model."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"models",children:"Models"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Index Model"})," - Used when adding new items (generates embeddings)."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Query Model"})," - Used when searching (generates query embeddings)."]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"You may configure both models separately, but they should be compatible."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"create-a-store",children:"Create a Store"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:'  create_store(\n    store="my_store",\n    index_model="all-minilm-l6-v2",\n    query_model="all-minilm-l6-v2",\n  )\n'})}),"\n",(0,s.jsx)(n.h2,{id:"insert-raw-input",children:"Insert Raw Input"}),"\n",(0,s.jsxs)(r,{children:[(0,s.jsx)("summary",{children:"Expand code"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:'response = await client.set(\n  ai_query.Set(\n      store="my_store",\n      inputs=[\n          keyval.AiStoreEntry(\n              key=keyval.StoreInput(raw_string="Jordan One"),\n              value=keyval.StoreValue(\n                  value={"brand": metadata.MetadataValue(raw_string="Nike")}\n              ),\n          ),\n          keyval.AiStoreEntry(\n              key=keyval.StoreInput(raw_string="Yeezey"),\n              value=keyval.StoreValue(\n                  value={"brand": metadata.MetadataValue(raw_string="Adidas")}\n              ),\n          )\n      ],\n      preprocess_action=preprocess.PreprocessAction.NoPreprocessing\n  )\n)\n'})})]}),"\n",(0,s.jsx)(n.h2,{id:"query-with-raw-input",children:"Query with Raw Input"}),"\n",(0,s.jsxs)(r,{children:[(0,s.jsx)("summary",{children:"Expand code"}),(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:'  response = await client.get_sim_n(\n    ai_query.GetSimN(\n        store="my_store",\n        search_input=keyval.StoreInput(raw_string="Jordan"),\n        closest_n=3,\n        algorithm=algorithms.Algorithm.COSINE_SIMILARITY,\n    )\n)\n\nfor entry in response.entries:\n    print(f"Key: {entry.key.raw_string}, Score: {entry.score}")\n'})})]}),"\n",(0,s.jsx)(n.p,{children:"Below is a breakdown of common AI request examples:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/ping",children:"Ping"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/info-server",children:"Info Server"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/list-stores",children:"List Stores"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/create-store",children:"Create Store"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/set",children:"Set"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/get-simn",children:"GetSimN"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/get-by-predicate",children:"Get By Predicate"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/create-predicate-index",children:"Create Predicate Index"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/drop-predicate-index",children:"Drop Predicate Index"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/delete-key",children:"Delete Key"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/drop-store",children:"Drop Store"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/create-non-linear-algx",children:"Create Non Linear Algorithm Index"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/client-libraries/python/request-ai/drop-non-linear-algx",children:"Drop Non Linear Algorithm Index"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},28453:(e,n,r)=>{r.d(n,{R:()=>l,x:()=>a});var i=r(96540);const s={},t=i.createContext(s);function l(e){const n=i.useContext(t);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);