---
title: ğŸ›ï¸ Architecture
sidebar_position: 60
---

# Ahnlich Architecture V2
**Status**: *Alpha / testing â€“ subject to breaking changes.***

Ahnlich is split into two independent, networkâ€‘accessible services that work in tandem:

- ahnlichâ€‘ai â€“ **the Intelligence Layer**
- ahnlichâ€‘db â€“ **the Vector Store Layer**

Clients can speak to either layer through gRPC/HTTP or the bundled CLI/SDKs. The AI layer adds automated embedding and model management on top of the raw vector store exposed by the DB layer.

## ğŸ“¦ 1.  Highâ€‘Level Design

```mermaid
flowchart TD

  subgraph ai [ahnlichâ€‘ai]

    direction TB

    AIClient["AI Client"]

    StoreHandlerAI["Store Handler"]

    StoreA_AI["Store A"]

    ModelNode["Index Model â†’ Model B<br/>Query Model â†’ Model A<br/>Preâ€‘process"]

    PersistenceAI[(Persistence)]

    AIClient --> |"original + metadata"| StoreHandlerAI

    StoreHandlerAI --> StoreA_AI

    StoreA_AI --> ModelNode

    ModelNode -.-> PersistenceAI

  end

  subgraph db [ahnlichâ€‘db]

    direction TB

    DBClient["DB Client"]

    StoreHandlerDB["Store Handler"]

    StoreA_DB["Store A"]

    PersistenceDB[(Persistence)]

    DBClient --> |"DB query"| StoreHandlerDB

    StoreHandlerDB --> StoreA_DB

    StoreA_DB -.-> PersistenceDB

  end


  %% Interâ€‘service calls

  StoreHandlerAI -.-> |"Set: vector + metadata"| StoreHandlerDB

  StoreHandlerAI -.-> |"GetSimN: vector"| StoreHandlerDB

  StoreHandlerDB -.-> |"Topâ€‘N results"| StoreHandlerAI

```

### Analogy to Kafka
| Kafka | Ahnlich | 
| ----- | ----- |
| **Producer** | AI Client / DB Client | 
| **Broker** | ahnlichâ€‘ai & ahnlichâ€‘db services | 
| **Topic / Partition** | Store (logical namespace) |
| **Message** | Vector + metadata |
| **Consumer** | Client fetching GetSimN |


## 2. Key Components
### 2.1  `ahnlichâ€‘ai` â€“ Intelligence Layer
| Subâ€‘component | Responsibility | 
| ----- | ----- |
| **AI Client API** | External gRPC/HTTP endpoints â€“ accepts raw documents (text, imagesâ€¦) & metadata. |
| **Store Handler** | Maps incoming requests to a Store; maintains perâ€‘store configuration (models, preprocess pipeline). | 
| **Store** | Logical namespace. Each holds a pair of ONNX models (Index & Query) plus preprocessing logic. | 
| **Model Node** | Executes preprocessing â†’ model inference â†’ produces embedding. |
| **Optional Persistence** | Periodic snapshots of store metadata & model cache to disk. |


### 2.2 `ahnlichâ€‘db` â€“ Vector Store Layer
| Subâ€‘component | Responsibility | 
| ----- | ----- |
| **DB Client API** | Accepts vectorâ€‘level commands: SET, GETSIMN, CREATESTORE, etc. |
| **Store Handler** | Routes to correct Store; enforces isolation; coordinates concurrent reads/writes. | 
| **Store (Vector Index)** | Inâ€‘memory index (bruteâ€‘force or KDâ€‘Tree) plus metadata map. Supports cosine & Euclidean similarity. | 
| **Filter Engine** | Applies boolean predicates on metadata during query. |
| **Optional Persistence** | Snapshots vectors & metadata to onâ€‘disk binary file for warm restarts. |


## 3.  Data Flow
### 3.1  Indexing (Write) Path
1. **Client** âœ AI Layer â€“ Sends raw document + metadata.
2. **Preprocessing & Embedding** â€“ AI layer cleans input, runs Index Model to yield vector.
3. **AI âœ DB** â€“ Issues SET carrying vector & metadata.
4. **DB Store** â€“ Writes vector into index, stores metadata.

### 3.2  Similarity Query Path
1. **Client âœ AI Layer** â€“ Provides search text/image.
2. **Embedding** â€“ AI layer runs Query Model to create search vector.
3. **AI âœ DB (GETSIMN)** â€“ Vector + algorithm + optional predicate.
4. **DB** â€“ Computes distance, applies metadata filter, returns Topâ€‘N IDs & scores.
5. **AI Layer** â€“ (Optional) postâ€‘processes or joins additional metadata before responding to client.

### 3.3  Direct DB Access
Advanced users can bypass AI and push preâ€‘computed vectors directly into ahnlichâ€‘db for maximum control.


## 4  Persistence & Durability
- **Optâ€‘in via** --enable-persistence.
- **Snapshot interval** configurable (--persistence-interval, default 300 s).
- **DB** writes a flat binary file; **AI** persists model cache & store manifests.
- On startup each service checks for the snapshot file and hydrates memory before accepting traffic.
- No replication yet; Ahnlich currently targets singleâ€‘node or sharedâ€‘nothing sharded deployments.

## 5. Scaling & Deployment Topologies
| Pattern | How it works | When to use | 
| ----- | ----- | ----- |
| **Singleâ€‘Node** | One `ahnlichâ€‘ai` & one `ahnlichâ€‘db` container (shown in README Compose). | Prototyping, local dev. |
| **Vertical Scaling** | Give DB more RAM/CPU; mount NVIDIA GPU for AI layer. | Medium workloads where a single node still fits in memory. | 
| **Storeâ€‘Level Sharding** | Run multiple DB instances, each owning a subset of Stores; fronted by one AI layer. | Multiâ€‘tenant SaaS or very large corpora. | 
| **Function Sharding** | Isolate heavy NLP image pipelines by model type: one AI instance per model group. | Heterogeneous workloads, GPU scheduling. |

**Roadmap**: clusterâ€‘wide replication & consistent hashing for transparent sharding.


## 6.  Observability
- Both services instrumented with **OpenTelemetry**; enable with --enable-tracing and send spans to Jaeger, Prometheus, etc.
- Internal metrics: query latency, index size, RAM usage, model inference time.


## 7.  Extensibility
- **Add a new similarity metric** â€“ implement SimAlgorithm trait in ahnlichâ€‘db.
- **Bring your own model** â€“ point ahnlichâ€‘ai to an ONNX file or HuggingFace repo via --supported-models.
- **Custom predicates** â€“ extend the predicate DSL to support regex or fullâ€‘text.


## 8.  Security Considerations
Currently no builtâ€‘in auth. Recommend placing behind an API gateway or reverse proxy that enforces:

- JWT / OAuth 2 bearer tokens.
- Mutual TLS between AI â‡„ DB if running across hosts.


## 9.  Limitations (July 2025)
- No distributed consensus â€“ durability limited to local snapshots.
- Singleâ€‘writer per Store lock may become a bottleneck under heavy concurrent writes.
- Model hotâ€‘swap requires store recreation.


## ğŸ” Summary
*Ahnlich decouples vector intelligence* (embedding generation, model lifecycle) from vector persistence & retrieval. This split allows you to scale and tune each layer independently while keeping a simple mental modelâ€”much like Kafka separates producers, brokers, and consumers around an immutable log.
